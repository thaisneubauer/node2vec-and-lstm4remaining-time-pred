{"cells":[{"cell_type":"markdown","source":["Author: Thais Rodrigues Neubauer\n","\n","This code trains and evaluate (with MAPE) regressors for the remaining time prediction task. Adapt the value of the variables in section \"Global variables\" to properly define paths and to control the characteristics of the model generation pipeline.\n","\n","The code was created to be executed using Google Colab. If that's not the case, delete the last two lines of the \"Import required libraries\" section."],"metadata":{"id":"zLJAaDOqdik2"}},{"cell_type":"markdown","metadata":{"id":"0ROX3tbCU04n"},"source":["#Import required libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26147,"status":"ok","timestamp":1710187040763,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"},"user_tz":300},"id":"yM7cCqU8gZH-","outputId":"273b8832-5e23-4499-9d3f-b318d6703089"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from __future__ import print_function, division\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Dense, LSTM, GRU, SimpleRNN, Input, BatchNormalization\n","#from keras.layers.core import Dense #depeding on the keras version, you may need this\n","#from keras.utils.data_utils import get_file\n","#from keras.optimizers import Nadam #use with tpu!\n","from keras.optimizers.legacy import Nadam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from lightgbm import LGBMRegressor\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn import metrics\n","import numpy as np\n","import pandas as pd\n","import time\n","import pickle\n","import ast\n","import os\n","import warnings"]},{"cell_type":"code","source":["###########################\n","# When using Google Colab #\n","###########################\n","from google.colab import files, drive\n","drive.mount('/content/gdrive/')"],"metadata":{"id":"GGML90jfme6V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Bg5Jj_BEiw3Q"},"source":["#Global variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V4aBGa70cr8u"},"outputs":[],"source":["##########################################\n","# Event log and resulting files controls #\n","##########################################\n","\n","DIR_PATH = '/content/gdrive/My Drive/ProcessMiningResearch/Interactive_trace_clustering/experiments_log_incidentes/rt_prediction/LSTM/'\n","DIR_PATH_MODELS = f'{DIR_PATH}output_files/models/'     #defines where the generated models will be saved\n","DIR_PATH_SUMMARIES = f'{DIR_PATH}output_files/results/' #defines where the evaluation files will be saved\n","EVENT_LOG = \"incidents.csv\" #\"helpdesk.csv\"\n","\n","CASE_COL = 'number'                  #'CaseID'             #column in the event log identifying the case\n","EVENT_TS_COL = 'sys_updated_on'      #'CompleteTimestamp'  #column identifying the event timestamp\n","ACTIVITY_NAME_COL = 'activity'       #'ActivityID'         #column identifying the activity name\n","ACTIVITY_ID_COL = 'activity_enc2int' #'ActivityID'         #column identifying the activity encoded to int\n","\n","\n","#################################\n","# Event representation controls #\n","#################################\n","\n","ASCII_OFFSET = 161    #used to transform the activities into characters during event representations building\n","\n","READ_TIME_ANNOTATED_LOG = True #False #define if the 4 time features are available in the informed event log file\n","TIME_ANNOTATED_LOG_FILE = f\"{DIR_PATH}data/{EVENT_LOG.replace('.csv','-time_annotated.csv')}\"\n","\n","TRF_VALUES = [False, True] #control of the inclusion of the 4 time related features in the event representation\n","EIF_VALUES = [False, True] #control of the inclusion of the event index (position) in the event representation\n","UAE_VALUES = [False, True] #control of the use of activity embeddings in the event representation\n","EMBEDDINGS_PATH = '/content/gdrive/My Drive/ProcessMiningResearch/Interactive_trace_clustering/experiments_log_incidentes/preprocess/graph_embeddings/results/activity_vecs/node2vec/'\n","EV_FILES = [file for file in os.listdir(EMBEDDINGS_PATH) if '.csv' in file and EVENT_LOG.replace('.csv','') in file and ('15d' in file) and 'attribsTrue' in file]\n","\n","ATTRIB_VALUES = [False, True]           #control if case attributes will be included in the event representation\n","ATTRIB_COLS = ['category','priority']   #column in the event log identifying the attributes to be included\n","EMBEDDING_ATTRIB = [False, True]        #control if when the case attributes are included, their embedding representation will be used\n","EMBEDDING_ATTRIB_PATH = '/content/gdrive/My Drive/ProcessMiningResearch/Interactive_trace_clustering/experiments_log_incidentes/preprocess/graph_embeddings/results/attrib_vecs/node2vec/'\n","\n","\n","#############################\n","# Models' training controls #\n","#############################\n","\n","TRAIN_PERC = 2/3                                                #define the ratio of the training set\n","MIN_PREFIX_LEN = 2                                              #define the minimum length of the prefixes\n","MODELS = ['LINEARREG', 'DECTREE', 'RNDFOREST', 'LGBM', 'LSTM']  #the algorithms to be used to generate regressors\n","LSTM_HIDDEN_LAYER_NEURONS = 100                                 #quantity of neurons of the LSTM hidden layer\n","RUNS = 3                              #quantity of models generated for each representation-algorithm combination"]},{"cell_type":"markdown","metadata":{"id":"jH3G5sTzUiTE"},"source":["# Data import and preparation"]},{"cell_type":"markdown","metadata":{"id":"lbpiFjE3VIbH"},"source":["Get existing sequences with the respective time features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gzJm-RGnWJbb"},"outputs":[],"source":["def add_sequence_info(case_events):\n","  def get_prefix_times_list(col_name):\n","    return case_events[col_name].astype(str).apply(lambda x: x+' ').cumsum().apply(lambda x: [float(n) for n in x.split(' ')[:-2]])\n","\n","  case_events = case_events.reset_index(drop=True).reset_index().rename(columns={'index':'PrefixLen'})\n","  case_events['Prefix'] = case_events.apply(lambda event: ''.join(case_events['ActivityChar'][:event['PrefixLen']].values) if event['PrefixLen'] >= MIN_PREFIX_LEN else None, axis = 1)\n","\n","  case_events['TimeSincePreviousEvent'] = (case_events[EVENT_TS_COL] - case_events[EVENT_TS_COL].shift().fillna(case_events[EVENT_TS_COL].iloc[0])).dt.total_seconds()\n","  case_events['PrefixTimesSincePreviousEvent'] = get_prefix_times_list('TimeSincePreviousEvent')\n","\n","  case_events['TimeSinceCaseStarted'] = (case_events[EVENT_TS_COL] -  case_events[EVENT_TS_COL].iloc[0]).dt.total_seconds()\n","  case_events['PrefixTimesSinceCaseStarted'] = get_prefix_times_list('TimeSinceCaseStarted')\n","\n","  case_events['Weekday'] = case_events[EVENT_TS_COL].dt.weekday\n","  case_events['PrefixWeekdays'] = get_prefix_times_list('Weekday')\n","\n","  case_events['SameDayTime'] = (case_events[EVENT_TS_COL] -  case_events[EVENT_TS_COL].dt.floor('D')).dt.total_seconds()\n","  case_events['PrefixSameDayTimes'] = get_prefix_times_list('SameDayTime')\n","\n","  case_events['RemainingTime'] = (case_events[EVENT_TS_COL].iloc[-1] - case_events[EVENT_TS_COL]).dt.total_seconds()\n","  case_events['PrefixRemainingTime'] = case_events['RemainingTime'].shift()\n","\n","  return case_events"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10276,"status":"ok","timestamp":1710187053757,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"},"user_tz":300},"id":"dMdXwWZ7WDRK","outputId":"ccc1c9d3-3f6a-4c75-b5a2-06a614b89787"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading annotated version of log from file...\n","Done!\n"]},{"output_type":"execute_result","data":{"text/plain":["   PrefixLen  0      number  activity_enc2int       sys_updated_on  \\\n","0          0  0  INC0000045                 6  2016-02-29 01:23:00   \n","1          1  1  INC0000045                 7  2016-02-29 08:53:00   \n","2          2  2  INC0000045                10  2016-02-29 11:29:00   \n","3          3  3  INC0000045                 5  2016-03-05 12:00:00   \n","4          0  4  INC0000047                 6  2016-02-29 04:57:00   \n","\n","                   activity             category incident_state      priority  \\\n","0                       New  Software - industry            New  3 - Moderate   \n","1                  Resolved  Software - industry       Resolved  3 - Moderate   \n","2  Update unknown attribute  Software - industry       Resolved  3 - Moderate   \n","3                    Closed  Software - industry         Closed  3 - Moderate   \n","4                       New        Remote access            New  3 - Moderate   \n","\n","  ActivityChar  ... TimeSincePreviousEvent  PrefixTimesSincePreviousEvent  \\\n","0            §  ...                    0.0                             []   \n","1            ¨  ...                27000.0                          [0.0]   \n","2            «  ...                 9360.0                 [0.0, 27000.0]   \n","3            ¦  ...               433860.0         [0.0, 27000.0, 9360.0]   \n","4            §  ...                    0.0                             []   \n","\n","  TimeSinceCaseStarted  PrefixTimesSinceCaseStarted Weekday   PrefixWeekdays  \\\n","0                  0.0                           []       0               []   \n","1              27000.0                        [0.0]       0            [0.0]   \n","2              36360.0               [0.0, 27000.0]       0       [0.0, 0.0]   \n","3             470220.0      [0.0, 27000.0, 36360.0]       5  [0.0, 0.0, 0.0]   \n","4                  0.0                           []       0               []   \n","\n","  SameDayTime          PrefixSameDayTimes RemainingTime  PrefixRemainingTime  \n","0      4980.0                          []      470220.0                  NaN  \n","1     31980.0                    [4980.0]      443220.0             470220.0  \n","2     41340.0           [4980.0, 31980.0]      433860.0             443220.0  \n","3     43200.0  [4980.0, 31980.0, 41340.0]           0.0             433860.0  \n","4     17820.0                          []      536580.0                  NaN  \n","\n","[5 rows x 21 columns]"],"text/html":["\n","  <div id=\"df-bbc4b134-aa6f-4749-add4-110ccfcd0937\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PrefixLen</th>\n","      <th>0</th>\n","      <th>number</th>\n","      <th>activity_enc2int</th>\n","      <th>sys_updated_on</th>\n","      <th>activity</th>\n","      <th>category</th>\n","      <th>incident_state</th>\n","      <th>priority</th>\n","      <th>ActivityChar</th>\n","      <th>...</th>\n","      <th>TimeSincePreviousEvent</th>\n","      <th>PrefixTimesSincePreviousEvent</th>\n","      <th>TimeSinceCaseStarted</th>\n","      <th>PrefixTimesSinceCaseStarted</th>\n","      <th>Weekday</th>\n","      <th>PrefixWeekdays</th>\n","      <th>SameDayTime</th>\n","      <th>PrefixSameDayTimes</th>\n","      <th>RemainingTime</th>\n","      <th>PrefixRemainingTime</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>INC0000045</td>\n","      <td>6</td>\n","      <td>2016-02-29 01:23:00</td>\n","      <td>New</td>\n","      <td>Software - industry</td>\n","      <td>New</td>\n","      <td>3 - Moderate</td>\n","      <td>§</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>[]</td>\n","      <td>0.0</td>\n","      <td>[]</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>4980.0</td>\n","      <td>[]</td>\n","      <td>470220.0</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>INC0000045</td>\n","      <td>7</td>\n","      <td>2016-02-29 08:53:00</td>\n","      <td>Resolved</td>\n","      <td>Software - industry</td>\n","      <td>Resolved</td>\n","      <td>3 - Moderate</td>\n","      <td>¨</td>\n","      <td>...</td>\n","      <td>27000.0</td>\n","      <td>[0.0]</td>\n","      <td>27000.0</td>\n","      <td>[0.0]</td>\n","      <td>0</td>\n","      <td>[0.0]</td>\n","      <td>31980.0</td>\n","      <td>[4980.0]</td>\n","      <td>443220.0</td>\n","      <td>470220.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>INC0000045</td>\n","      <td>10</td>\n","      <td>2016-02-29 11:29:00</td>\n","      <td>Update unknown attribute</td>\n","      <td>Software - industry</td>\n","      <td>Resolved</td>\n","      <td>3 - Moderate</td>\n","      <td>«</td>\n","      <td>...</td>\n","      <td>9360.0</td>\n","      <td>[0.0, 27000.0]</td>\n","      <td>36360.0</td>\n","      <td>[0.0, 27000.0]</td>\n","      <td>0</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>41340.0</td>\n","      <td>[4980.0, 31980.0]</td>\n","      <td>433860.0</td>\n","      <td>443220.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>INC0000045</td>\n","      <td>5</td>\n","      <td>2016-03-05 12:00:00</td>\n","      <td>Closed</td>\n","      <td>Software - industry</td>\n","      <td>Closed</td>\n","      <td>3 - Moderate</td>\n","      <td>¦</td>\n","      <td>...</td>\n","      <td>433860.0</td>\n","      <td>[0.0, 27000.0, 9360.0]</td>\n","      <td>470220.0</td>\n","      <td>[0.0, 27000.0, 36360.0]</td>\n","      <td>5</td>\n","      <td>[0.0, 0.0, 0.0]</td>\n","      <td>43200.0</td>\n","      <td>[4980.0, 31980.0, 41340.0]</td>\n","      <td>0.0</td>\n","      <td>433860.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>INC0000047</td>\n","      <td>6</td>\n","      <td>2016-02-29 04:57:00</td>\n","      <td>New</td>\n","      <td>Remote access</td>\n","      <td>New</td>\n","      <td>3 - Moderate</td>\n","      <td>§</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>[]</td>\n","      <td>0.0</td>\n","      <td>[]</td>\n","      <td>0</td>\n","      <td>[]</td>\n","      <td>17820.0</td>\n","      <td>[]</td>\n","      <td>536580.0</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 21 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbc4b134-aa6f-4749-add4-110ccfcd0937')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bbc4b134-aa6f-4749-add4-110ccfcd0937 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bbc4b134-aa6f-4749-add4-110ccfcd0937');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c88dfe3b-d233-46ee-aa2a-45fcbed10f12\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c88dfe3b-d233-46ee-aa2a-45fcbed10f12')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c88dfe3b-d233-46ee-aa2a-45fcbed10f12 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"DF"}},"metadata":{},"execution_count":4}],"source":["if READ_TIME_ANNOTATED_LOG:\n","  print('Reading annotated version of log from file...')\n","  list_cols = ['PrefixTimesSincePreviousEvent', 'PrefixTimesSinceCaseStarted', 'PrefixWeekdays', 'PrefixSameDayTimes']\n","  DF = pd.read_csv(TIME_ANNOTATED_LOG_FILE, converters={col: ast.literal_eval for col in list_cols})\n","  print('Done!')\n","else:\n","  print('Creating annotated version of log...')\n","  DF = pd.read_csv(f'{DIR_PATH}data/{EVENT_LOG}')\n","  DF[EVENT_TS_COL] = pd.to_datetime(DF[EVENT_TS_COL])\n","\n","  ASCII_OFFSET = 161\n","  DF['ActivityChar'] = DF[ACTIVITY_ID_COL].apply(lambda activity: chr(int(activity)+ASCII_OFFSET))\n","\n","  DF = DF.groupby(CASE_COL, group_keys=False).apply(add_sequence_info).reset_index(drop=True)\n","  DF.to_csv(TIME_ANNOTATED_LOG_FILE, index=False)\n","  print('Done!')\n","DF.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":99,"status":"ok","timestamp":1710187053853,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"},"user_tz":300},"id":"5niu1z9eLwI5","outputId":"21be65fc-db81-4f47-bda6-e569a59b4d8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["total chars: 11\n","{0: '¡', 1: '¢', 2: '£', 3: '¤', 4: '¥', 5: '¦', 6: '§', 7: '¨', 8: '©', 9: 'ª', 10: '«'}\n"]}],"source":["CHARS = map(lambda x: set(x), DF['Prefix'].dropna().values)\n","CHARS = list(set().union(*CHARS))\n","CHARS.sort()\n","print('total chars: {}'.format(len(CHARS)))\n","CHARS_INDICES = dict((c, i) for i, c in enumerate(CHARS))\n","INDICES_CHARS = dict((i, c) for i, c in enumerate(CHARS))\n","print(INDICES_CHARS)\n","\n","MAXLEN = max(DF['Prefix'].dropna().apply(lambda x: len(x)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1710187053853,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"},"user_tz":300},"id":"Q5kjAwjmUTU0","outputId":"8bed9a77-766a-49c5-c35b-a9b960fc25fa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{10: 'Update unknown attribute',\n"," 7: 'Resolved',\n"," 5: 'Closed',\n"," 0: 'Active',\n"," 6: 'New',\n"," 3: 'Awaiting User Info',\n"," 8: 'Update category',\n"," 9: 'Update priority',\n"," 4: 'Awaiting Vendor',\n"," 2: 'Awaiting Problem',\n"," 1: 'Awaiting Evidence'}"]},"metadata":{},"execution_count":6}],"source":["ACT_ID2STR = None\n","if ACTIVITY_NAME_COL != ACTIVITY_ID_COL:\n","  ACT_ID2STR =  DF[[ACTIVITY_ID_COL,ACTIVITY_NAME_COL]].value_counts().index.to_list()\n","  ACT_ID2STR = {act_enc2int:act_name for act_enc2int, act_name in ACT_ID2STR}\n","else:\n","  ACT_ID2STR = {id:str(id) for id in list(DF[ACTIVITY_ID_COL].unique())}\n","ACT_ID2STR"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UVeoYl38DSd1"},"outputs":[],"source":["ATTRIB_ENCODERS = []\n","ATTRIB_NDIMENSIONS = 0\n","\n","for attrib in ATTRIB_COLS:\n","  le = LabelEncoder()\n","  le.fit(DF[attrib])\n","  ATTRIB_NDIMENSIONS += len(le.classes_)\n","  ATTRIB_ENCODERS.append(le)"]},{"cell_type":"markdown","metadata":{"id":"EYku8nNJCscx"},"source":["##Train-test split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d9RvF2Nwg3Lo"},"outputs":[],"source":["#The correct option here would be to filter out the event with less the MIN_PREFIX_LEN now, before splitting train and test sets\n","#However, to keep the same values applied by Tax et al, we'll maintain the filtering after the train/test split\n","#df_seq = df.dropna(subset='Prefix')\n","#cases = list(df_seq[CASE_COL].unique())\n","cases = list(DF[CASE_COL].unique())\n","TRAIN_CASES = list(cases)[:int(len(cases)*TRAIN_PERC)]\n","TEST_CASES =  list(cases)[int(len(cases)*TRAIN_PERC):]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":709,"status":"ok","timestamp":1710187054643,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"},"user_tz":300},"id":"AfFT2oDYOS-H","outputId":"c34e3e6a-baac-47b9-fdd1-7ae7bd0e9abb"},"outputs":[{"output_type":"stream","name":"stdout","text":["137890.74259206429 484882.44446373865\n"]}],"source":["tspe_per_case = DF[DF[CASE_COL].isin(TRAIN_CASES)].groupby(CASE_COL)['TimeSincePreviousEvent'].agg(list).values\n","TSPE_NORMALIZER = np.mean([t for case_ts in tspe_per_case for t in case_ts[:-1] if len(case_ts) > 2])\n","tscs_per_case = DF[DF[CASE_COL].isin(TRAIN_CASES)].groupby(CASE_COL)['TimeSinceCaseStarted'].agg(list).values\n","TSCS_NORMALIZER = np.mean([t for case_ts in tscs_per_case for t in case_ts[:-1] if len(case_ts) > 2])\n","print(TSPE_NORMALIZER, TSCS_NORMALIZER)"]},{"cell_type":"markdown","metadata":{"id":"gydkxq-xro5Y"},"source":["#Aux Functions"]},{"cell_type":"markdown","metadata":{"id":"IUYyOGJu7h9V"},"source":["## Get vector representation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxKsmI4jPSGM"},"outputs":[],"source":["def get_sentences(case_ids_list, time_related_features, attrib_features):\n","  case_ids = list(DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset='Prefix')[CASE_COL])\n","  prefixes = list(DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset='Prefix')['PrefixLen'])\n","  sentences = list(DF[DF[CASE_COL].isin(case_ids_list)]['Prefix'].dropna().values)\n","  sentences_rt = list(DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset='Prefix')['PrefixRemainingTime'].dropna())\n","  sentences_t = sentences_t2 = sentences_t3 = sentences_t4 = sentences_attrib = None\n","  if time_related_features:\n","    sentences_t = list(DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset=['Prefix'])['PrefixTimesSincePreviousEvent'].values)\n","    sentences_t2 = list(DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset=['Prefix'])['PrefixTimesSinceCaseStarted'])\n","    sentences_t3 = list(DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset=['Prefix'])['PrefixSameDayTimes'])\n","    sentences_t4 = list(DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset=['Prefix'])['PrefixWeekdays'])\n","  if attrib_features:\n","    sentences_attrib = DF[DF[CASE_COL].isin(case_ids_list)].dropna(subset=['Prefix'])[ATTRIB_COLS].values\n","  return case_ids, prefixes, sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4, sentences_attrib, sentences_rt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRrACuUOpRAr"},"outputs":[],"source":["def get_vector_repres(cases_ids_list, event_index_feature, time_related_features, attrib_features, use_attrib_embedding,\n","                      use_act_embedding, act_embedding_filename, algorithm):\n","\n","  def get_embedding_info(use_embedding, path, embedding_filename, embedding_id_col): #node type is either 'activity' or 'attribute'\n","    embeddings = None\n","    embedding_size = None\n","    if use_embedding:\n","      embeddings = pd.read_csv(f'{path}{embedding_filename}')\n","      embeddings[embedding_id_col] = embeddings[embedding_id_col].astype(str)\n","      embedding_size = [int(part.replace('d','')) for part in embedding_filename.split('_') if part[-1]=='d'][0]\n","    return embeddings, embedding_size\n","\n","  def get_num_features():\n","    n = len(DF[ACTIVITY_ID_COL].unique())\n","    if use_act_embedding:\n","      n = act_embedding_size\n","    if event_index_feature:\n","      n += 1\n","    if time_related_features:\n","      n += 4\n","    if attrib_features:\n","      if use_attrib_embedding:\n","        n += np.array(attribs_embedding_size).sum()\n","      else:\n","        n += ATTRIB_NDIMENSIONS\n","    return n\n","\n","  def get_linearized_X(X):\n","    new_X = [sequence_events.sum(axis=0) for sequence_events in X]\n","    #for concatenating instead of summing up event features:\n","    #new_X = []\n","    #for sequence in X:\n","      #new_X.append([event_features for event in sequence for event_features in event])\n","    return new_X\n","\n","  act_embeddings, act_embedding_size = get_embedding_info(use_act_embedding, EMBEDDINGS_PATH, act_embedding_filename, 'activity')\n","\n","\n","  attribs_embedding_size = []\n","  attribs_embeddings = []\n","  for i, attrib in enumerate(ATTRIB_COLS):\n","    #the graph embedding version for the attributes is always the same as the activity, just with the attribute name in the beggining\n","    attrib_embeddings, attrib_embedding_size = get_embedding_info(use_attrib_embedding, EMBEDDING_ATTRIB_PATH, f'{attrib}_{act_embedding_filename}',\n","                                                                  attrib)\n","    attribs_embeddings.append(attrib_embeddings)\n","    attribs_embedding_size.append(attrib_embedding_size)\n","\n","  num_features = get_num_features()\n","\n","\n","  case_ids, prefixes, sentences, sentences_t, sentences_t2, sentences_t3, sentences_t4, sentences_attrib, sentences_rt = get_sentences(cases_ids_list, time_related_features, attrib_features)\n","\n","  X = np.zeros((len(sentences), MAXLEN, num_features), dtype=np.float32)\n","  y_rt = np.zeros((len(sentences)), dtype=np.float32)\n","\n","  for i, sentence in enumerate(sentences):\n","      len_sentence = len(sentence)\n","      leftpad = MAXLEN-len_sentence\n","      if time_related_features:\n","        sentence_t = sentences_t[i]\n","        sentence_t2 = sentences_t2[i]\n","        sentence_t3 = sentences_t3[i]\n","        sentence_t4 = sentences_t4[i]\n","      if attrib_features:\n","        sentence_attrib = sentences_attrib[i]\n","\n","      for t, char in enumerate(sentence):\n","\n","          next_pos = 0\n","\n","          if use_act_embedding:\n","              X[i,t+leftpad, next_pos:act_embedding_size] = act_embeddings[act_embeddings.activity == ACT_ID2STR[ord(char)-ASCII_OFFSET]].set_index('activity').values[0]\n","              next_pos = act_embedding_size\n","          else: #not applying embeddings to represent activities - one hot encoding will be applied instead\n","            for c in CHARS:\n","                if c==char: #this will encode present events to the right places\n","                    X[i, t+leftpad, next_pos+CHARS_INDICES[c]] = 1\n","            next_pos = len(CHARS)\n","\n","          if event_index_feature:\n","            X[i, t+leftpad, next_pos] = t+1\n","            next_pos += 1\n","\n","          if time_related_features:\n","            X[i, t+leftpad, next_pos] = sentence_t[t]/TSPE_NORMALIZER\n","            X[i, t+leftpad, next_pos+1] = sentence_t2[t]/TSCS_NORMALIZER\n","            X[i, t+leftpad, next_pos+2] = sentence_t3[t]/86400\n","            X[i, t+leftpad, next_pos+3] = sentence_t4[t]/7\n","            next_pos += 4\n","\n","          if attrib_features:\n","            for attrib_pos, attrib_value in enumerate(sentence_attrib):\n","              if use_attrib_embedding:\n","                #try to find the activity, otherwise, leave it with all zeros\n","                if len(attribs_embeddings[attrib_pos][attribs_embeddings[attrib_pos][ATTRIB_COLS[attrib_pos]] == attrib_value]) > 0:\n","                  X[i,t+leftpad, next_pos:next_pos+attribs_embedding_size[attrib_pos]] = attribs_embeddings[attrib_pos][attribs_embeddings[attrib_pos][ATTRIB_COLS[attrib_pos]] == attrib_value].set_index(ATTRIB_COLS[attrib_pos]).values[0]\n","              else:\n","                X[i, t+leftpad, next_pos + ATTRIB_ENCODERS[attrib_pos].transform([attrib_value])[0]] = 1\n","            next_pos += 1\n","\n","\n","      y_rt[i] = sentences_rt[i]\n","\n","  if algorithm != 'LSTM':\n","    X = get_linearized_X(X)\n","  return case_ids, prefixes, X, y_rt, num_features\n"]},{"cell_type":"markdown","metadata":{"id":"x6osUXDSc_6M"},"source":["##Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I57wKj0Bo62K"},"outputs":[],"source":["def train(algorithm, X, y, max_len, num_features, test_id):\n","  def get_model(filename, model_file, train_function, *train_args):\n","    if algorithm == 'LSTM' and filename in os.listdir(f'{DIR_PATH_MODELS}{algorithm}{LSTM_HIDDEN_LAYER_NEURONS}/'):\n","        model = load_model(model_file)\n","        print('Existing model loaded!')\n","        return model, 0\n","    elif algorithm != 'LSTM' and filename in os.listdir(f'{DIR_PATH_MODELS}{algorithm}/'):\n","      model = pickle.load(open(model_file, 'rb'))\n","      print('Existing model loaded!')\n","      return model, 0\n","    print('Training model...')\n","    starttime = time.time()\n","    model = train_function(*train_args)\n","    runt = time.time() - starttime\n","    print(f'Done in {runt}!')\n","    return model, runt\n","\n","  path = f'{DIR_PATH_MODELS}{algorithm}/'\n","  if algorithm == 'LSTM':\n","    path = f'{DIR_PATH_MODELS}{algorithm}{LSTM_HIDDEN_LAYER_NEURONS}/'\n","    filename = f'{test_id}.h5'\n","    return get_model(filename, f'{path}{filename}', train_LSTM, X, y, max_len, num_features, filename)\n","\n","  #if not LSTM, all other model behave the same\n","  filename = f'{test_id}.pickle'\n","  model_file = f'{path}{filename}'\n","  if algorithm == 'LGBM':\n","    return get_model(filename, model_file, train_default, X, y, LGBMRegressor, model_file)\n","  if algorithm == 'RNDFOREST':\n","    return get_model(filename, model_file, train_default, X, y, RandomForestRegressor, model_file)\n","  if algorithm == 'DECTREE':\n","    return get_model(filename, model_file, train_default, X, y, DecisionTreeRegressor, model_file)\n","  if algorithm == 'LINEARREG':\n","    return get_model(filename, model_file, train_default, X, y, LinearRegression, model_file)\n","\n","  print(f'{algorithm} not among the expected models :(')\n","  return None, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cK_6yrP5QfLz"},"outputs":[],"source":["def train_default(X, y, creation_func, file_path):\n","  model = creation_func()\n","  if 'LINEARREG' not in file_path: #inicialize model with a seed\n","    model = creation_func(random_state=int(file_path.split('#RUN')[-1][0])) #define seed based on the run id\n","  model.fit(X,y)\n","  pickle.dump(model, open(file_path,'wb'))\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":189,"status":"ok","timestamp":1710187054999,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"},"user_tz":300},"id":"CMPPOdFvhIKi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4c015b4-43c1-45d5-f9cd-736aed4bd4e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/device:GPU:0\n"]}],"source":["tf.config.experimental.enable_op_determinism()\n","if tf.test.gpu_device_name() != '':\n","  print(tf.test.gpu_device_name())\n","  tf.device(tf.test.gpu_device_name())\n","\n","def train_LSTM(X, y, max_len, num_features, model_filename):\n","  keras.utils.set_random_seed(int(model_filename.split('#RUN')[-1][0]))\n","  main_input = Input(shape=(max_len, num_features), name='main_input')\n","  l_rt = LSTM(LSTM_HIDDEN_LAYER_NEURONS, implementation=2, kernel_initializer='glorot_uniform', return_sequences=False, dropout=0.2)(main_input) # the layer specialized in time prediction\n","  b_rt = BatchNormalization()(l_rt)\n","  time_output = Dense(1, kernel_initializer='glorot_uniform', name='time_output')(b_rt)\n","\n","  model = Model(inputs=[main_input], outputs=[time_output])\n","\n","  opt = Nadam(learning_rate=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004, clipvalue=3)\n","\n","  model.compile(loss={'time_output':'mae'}, optimizer=opt)\n","  #model = use_tpu(model)\n","  early_stopping = EarlyStopping(monitor='val_loss', patience=42)\n","  model_checkpoint = ModelCheckpoint('output_files/models/model_{epoch:02d}-{val_loss:.2f}.h5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n","  lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n","\n","  model.fit(X, {'time_output':y}, validation_split=0.2, verbose=0, callbacks=[early_stopping, model_checkpoint, lr_reducer], batch_size=max_len, epochs=500)\n","  model.save(f'{DIR_PATH_MODELS}LSTM{LSTM_HIDDEN_LAYER_NEURONS}/{model_filename}')\n","  return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_EEYAC4XWyQ"},"outputs":[],"source":["def train_and_evaluate(algorithm, test_id, time_related_features, event_index_features,\n","                       attrib_features, use_attrib_embedding, use_embedding, act_embedding_filename):\n","\n","  def get_error(y, y_pred, only_positive=False):\n","    if algorithm == 'LSTM':\n","      y_pred = [yi[0] for yi in y_pred]\n","    if only_positive:\n","      y_pred = [yi if yi > 0 else 0 for yi in y_pred]\n","    return y_pred, metrics.mean_absolute_error(y, y_pred)\n","\n","\n","  if (test_id+'.h5' in os.listdir(f'{DIR_PATH_MODELS}LSTM{LSTM_HIDDEN_LAYER_NEURONS}/')):\n","    print('next!')\n","    return\n","\n","  _, _, X_train, y_train, num_features = get_vector_repres(TRAIN_CASES, event_index_features, time_related_features,\n","                                                           attrib_features, use_attrib_embedding,\n","                                                           use_act_embedding, act_embedding_filename, algorithm)\n","\n","  model, rtime = train(algorithm, X_train, y_train, MAXLEN, num_features, test_id)\n","\n","  _, resubstitution_error = get_error(y_train, model.predict(X_train))\n","\n","  #test\n","  case_ids, prefixes, X_test, y_test, _ = get_vector_repres(TEST_CASES,  event_index_features, time_related_features,\n","                                                            attrib_features, use_attrib_embedding,\n","                                                            use_act_embedding, act_embedding_filename, algorithm)\n","\n","  y_pred = model.predict(X_test)\n","  y_pred, test_error = get_error(y_test, y_pred)\n","  pred_prefix_df = pd.DataFrame({'prefix': prefixes, 'y_ground_truth': y_test, 'y_pred': y_pred})\n","  avg_per_prefix = pred_prefix_df.groupby('prefix').apply(lambda x: metrics.mean_absolute_error(x['y_ground_truth'], x['y_pred']))\n","\n","  log_result(test_id, algorithm, event_index_features, time_related_features, attrib_features, use_attrib_embedding,\n","             use_embedding, act_embedding_filename, y_pred, avg_per_prefix.sort_index(),\n","             resubstitution_error, test_error)\n","  #save results\n","  result = pd.DataFrame({CASE_COL: case_ids, 'Prefix length': prefixes, 'Ground truth': y_test, 'Predicted times': y_pred})\n","  result['Execution Training Time'] = rtime\n","  if algorithm == 'LSTM':\n","    result.to_csv(f'{DIR_PATH_SUMMARIES}{algorithm}{LSTM_HIDDEN_LAYER_NEURONS}/{test_id}.csv', index=False)\n","  else:\n","    result.to_csv(f'{DIR_PATH_SUMMARIES}{algorithm}/{test_id}.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"ioXe-b2XGnVH"},"source":["## Save results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"izhZ3OezGqHJ"},"outputs":[],"source":["def log_result(test_id, algorithm, event_index_features, time_related_features, attrib_features, use_attrib_embedding,\n","               use_embedding, act_embedding_filename, y_pred, avg_per_prefix, resubstitution_error, test_error):\n","\n","  PREDICTIONS[test_id] = y_pred\n","\n","  DF_TEST_IDS.append(test_id)\n","  DF_PRED_ALG.append(algorithm)\n","  DF_EVENT_POS.append(event_index_features)\n","  DF_TIME_FEATURES.append(time_related_features)\n","  DF_ACT_EMB.append(act_embedding_filename)\n","  #node2vec_3d_P3.0-helpdesk-time_annotated--evntTrue_evntposTrue_timesTrue\n","  if 'evntposTrue' in test_id:\n","    DF_ACT_EMB_EVENT_POS.append(True)\n","  else:\n","    DF_ACT_EMB_EVENT_POS.append(False)\n","  if 'timesTrue' in test_id:\n","    DF_ACT_EMB_TIME_FEAT.append(True)\n","  else:\n","    DF_ACT_EMB_TIME_FEAT.append(False)\n","  DF_CASE_ATTRIB.append(attrib_features)\n","  if attrib_features:\n","    DF_ATTRIBS_COLS.append(', '.join(ATTRIB_COLS))\n","  else:\n","    DF_ATTRIBS_COLS.append('')\n","  if use_attrib_embedding:\n","    DF_ATTRIBS_EMBEDDINGS.append(True)\n","  else:\n","    DF_ATTRIBS_EMBEDDINGS.append(False)\n","  DF_RESUB_ERRORS.append(resubstitution_error/60/60/24)\n","  DF_TEST_ERRORS.append(test_error/60/60/24)\n","  avgs_prefixes = avg_per_prefix.values\n","  for i,avg_prefix in enumerate(avgs_prefixes):\n","    prefix_id = f'Prefix {i+MIN_PREFIX_LEN} avg'\n","    if prefix_id not in DF_AVG_PREFIX:\n","      DF_AVG_PREFIX[prefix_id] = []\n","    DF_AVG_PREFIX[prefix_id].append(avg_prefix/60/60/24)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7GypsvlOTxSl"},"outputs":[],"source":["def save_results():\n","  print('Saving results...')\n","  pd.DataFrame(PREDICTIONS).to_csv(f\"{DIR_PATH_SUMMARIES}/all_predictions.csv\", index=False)\n","  dict_all = {'Test id': DF_TEST_IDS, 'Prediction Algorithm': DF_PRED_ALG,\n","                 'Event position': DF_EVENT_POS, 'Time features': DF_TIME_FEATURES, 'Activity embeddings': DF_ACT_EMB,\n","                 'Case attributes': DF_CASE_ATTRIB, 'Attributes names': DF_ATTRIBS_COLS, 'Attributes embeddings': DF_ATTRIBS_EMBEDDINGS,\n","                 'Graph with event position node': DF_ACT_EMB_EVENT_POS, 'Graph with time nodes':DF_ACT_EMB_TIME_FEAT,\n","                 'Resubstitution error': DF_RESUB_ERRORS, 'Test error': DF_TEST_ERRORS}\n","  dict_all.update(DF_AVG_PREFIX)\n","  df = pd.DataFrame(dict_all).to_csv(f\"{DIR_PATH_SUMMARIES}/metadata.csv\", index=False)\n","  print(f'Done! Files saved to {DIR_PATH_SUMMARIES}')"]},{"cell_type":"markdown","metadata":{"id":"3UWeLhYXVnsR"},"source":["#Train and evaluate\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yQ_EtPyHehR"},"outputs":[],"source":["case_ids, prefixes, _, y_test, _ = get_vector_repres(TEST_CASES,  False, False, False, False, False, None, '')\n","PREDICTIONS = {'case_id': case_ids, 'prefixes_len': prefixes, 'y_test': y_test}\n","DF_TEST_IDS = []\n","DF_PRED_ALG = []\n","DF_EVENT_POS = []\n","DF_TIME_FEATURES = []\n","DF_ACT_EMB = []\n","DF_CASE_ATTRIB = []\n","DF_ATTRIBS_EMBEDDINGS = []\n","DF_ATTRIBS_COLS = []\n","DF_ACT_EMB_EVENT_POS = []\n","DF_ACT_EMB_TIME_FEAT = []\n","DF_AVG_PREFIX = {}\n","DF_RESUB_ERRORS = []\n","DF_TEST_ERRORS = []"]},{"cell_type":"code","source":["print('Algorithms:', MODELS)\n","print('Neuroms hidden layer LSTM:', LSTM_HIDDEN_LAYER_NEURONS)\n","print('Time related features:', TRF_VALUES)\n","print('Event position:', TRF_VALUES)\n","print('Case attributes:', ATTRIB_VALUES)\n","print('Use embedding for activity representation:', UAE_VALUES)\n","print('Embedding files:', EV_FILES)\n","print('#Runs per model-representation:', RUNS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MN0v5h9eeTjC","executionInfo":{"status":"ok","timestamp":1710187055470,"user_tz":300,"elapsed":3,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"}},"outputId":"dc1176df-43c0-4c1c-e306-64f0a96072c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Algorithms: ['LSTM']\n","Neuroms hidden layer LSTM: 100\n","Time related features: [True]\n","Event position: [True]\n","Case attributes: [True]\n","Use embedding for activity representation: [False]\n","Embedding files: ['node2vec_15d_P3.0-incidents-time_annotated--evntTrue_evntposFalse_timesFalse_attribsTrue#RUN1.csv', 'node2vec_15d_P3.0-incidents-time_annotated--evntTrue_evntposFalse_timesFalse_attribsTrue.csv', 'node2vec_15d_P3.0-incidents-time_annotated--evntTrue_evntposFalse_timesFalse_attribsTrue#RUN2.csv']\n","#Runs per model-representation: 3\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MF_aXeCG4lSH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710188877807,"user_tz":300,"elapsed":1822339,"user":{"displayName":"Thais Rodrigues Neubauer","userId":"03562214994457129962"}},"outputId":"f3075b7b-2fb8-4c4d-c9ff-5d0e08adbaf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test id: (1, 'incidents-LSTM-TRF_1-EIF_1-ATTRIB_cat#RUN0')\n","Training model...\n","Done in 541.7044610977173!\n","2045/2045 [==============================] - 7s 3ms/step\n","838/838 [==============================] - 3s 4ms/step\n","\n","Test id: (2, 'incidents-LSTM-TRF_1-EIF_1-ATTRIB_cat#RUN1')\n","Training model...\n","Done in 530.828629732132!\n","2045/2045 [==============================] - 6s 3ms/step\n","838/838 [==============================] - 3s 3ms/step\n","\n","Test id: (3, 'incidents-LSTM-TRF_1-EIF_1-ATTRIB_cat#RUN2')\n","Training model...\n","Done in 530.4994513988495!\n","2045/2045 [==============================] - 6s 3ms/step\n","838/838 [==============================] - 3s 4ms/step\n","Saving results...\n","Done! Files saved to /content/gdrive/My Drive/ProcessMiningResearch/Interactive_trace_clustering/experiments_log_incidentes/rt_prediction/LSTM/output_files/results/\n"]}],"source":["i = 0\n","for algorithm in MODELS:\n","  for time_related_features in TRF_VALUES:\n","    for event_index_features in EIF_VALUES:\n","      for attrib_features in ATTRIB_VALUES:\n","        for use_attrib_embedding in EMBEDDING_ATTRIB:\n","          for use_act_embedding in UAE_VALUES:\n","            for embedding_version in EV_FILES:\n","              for run in range(0,RUNS):\n","                i+=1\n","                test_id = f\"{EVENT_LOG.replace('.csv','')}-{algorithm}-TRF_{int(time_related_features)}-EIF_{int(event_index_features)}\"\n","                if attrib_features:\n","                  test_id += f\"-ATTRIB_{'$'.join([col[:3] for col in ATTRIB_COLS])}\"\n","                  if use_attrib_embedding:\n","                      test_id += f\"_EMBED\"\n","                if use_act_embedding:\n","                  test_id += f\"-{embedding_version.replace('-'+EVENT_LOG.replace('.csv',''),'').replace('node2vec_','').replace('.csv','')}\"\n","                else:\n","                  embedding_version = \"\"\n","                test_id +=f\"#RUN{run}\"\n","                print(f\"\\nTest id: {i, test_id}\")\n","                train_and_evaluate(algorithm, test_id, time_related_features, event_index_features,\n","                                  attrib_features, use_attrib_embedding,\n","                                  use_act_embedding, embedding_version)\n","                if algorithm == 'LINEARREG': #do not need to run 3 times!\n","                  break\n","              if not use_act_embedding:\n","                break #do not need the loop of the embedding files\n","save_results()"]}],"metadata":{"colab":{"collapsed_sections":["0ROX3tbCU04n","Bg5Jj_BEiw3Q","jH3G5sTzUiTE","IUYyOGJu7h9V","ioXe-b2XGnVH"],"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}